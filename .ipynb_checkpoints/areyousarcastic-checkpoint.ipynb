{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49c9d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/gsm66h1s69353__mqd3hpy9w0000gn/T/ipykernel_5682/2207169692.py:6: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n",
      "2023-07-21 09:31:05.139339: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# pandas to open data files & processing it.\n",
    "import pandas as pd\n",
    "# to see all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# To see whole text\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "# numpy for numeric data processing\n",
    "import numpy as np\n",
    "\n",
    "# keras for deep learning model creation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# to fix random seeds\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Regular Expression for text cleaning\n",
    "import re\n",
    "\n",
    "# to track the progress - progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3516bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010826, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams more than east teams right?</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york nigga\" ones are.</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0  0       \n",
       "1  0       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       \n",
       "\n",
       "                                                                                                                     comment  \\\n",
       "0  NC and NH.                                                                                                                  \n",
       "1  You do know west teams play against west teams more than east teams right?                                                  \n",
       "2  They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1   \n",
       "3  This meme isn't funny none of the \"new york nigga\" ones are.                                                                \n",
       "4  I could use one of those tools.                                                                                             \n",
       "\n",
       "      author           subreddit  score  ups  downs     date  \\\n",
       "0  Trumpbart  politics            2     -1   -1      2016-10   \n",
       "1  Shbshb906  nba                -4     -1   -1      2016-11   \n",
       "2  Creepeth   nfl                 3      3    0      2016-09   \n",
       "3  icebrotha  BlackPeopleTwitter -8     -1   -1      2016-10   \n",
       "4  cush2push  MaddenUltimateTeam  6     -1   -1      2016-12   \n",
       "\n",
       "           created_utc  \\\n",
       "0  2016-10-16 23:55:23   \n",
       "1  2016-11-01 00:24:10   \n",
       "2  2016-09-22 21:45:37   \n",
       "3  2016-10-18 21:03:47   \n",
       "4  2016-12-30 17:00:13   \n",
       "\n",
       "                                                                                                                           parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.                                                        \n",
       "1  The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.  \n",
       "2  They're favored to win.                                                                                                                 \n",
       "3  deadass don't kill my buzz                                                                                                              \n",
       "4  Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT                                                   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_data = pd.read_csv(\"file:///Users/Tahora/Downloads/train-balanced-sarcasm.csv\")\n",
    "print(sarcasm_data.shape)\n",
    "sarcasm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ab399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams more than east teams right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york nigga\" ones are.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0  0       \n",
       "1  0       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       \n",
       "\n",
       "                                                                                                                     comment  \n",
       "0  NC and NH.                                                                                                                 \n",
       "1  You do know west teams play against west teams more than east teams right?                                                 \n",
       "2  They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1  \n",
       "3  This meme isn't funny none of the \"new york nigga\" ones are.                                                               \n",
       "4  I could use one of those tools.                                                                                            "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_data.drop(['author', 'subreddit', 'score', 'ups', 'downs', 'date', 'created_utc', 'parent_comment'], axis=1, inplace=True)\n",
    "# remove empty rows\n",
    "sarcasm_data.dropna(inplace=True)\n",
    "sarcasm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ac50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_data.to_csv('sarcasm_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7f0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {\"ain't\": \"is not\", \"cannot\": \"can not\", \"aren't\": \"are not\", \"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "                \"doesn't\": \"does not\",\n",
    "                \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
    "                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\",\n",
    "                \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n",
    "                \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\", \"they'd\": \"they would\",\n",
    "                \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
    "                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "                \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\",\n",
    "                \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"wont\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
    "                \"wouldn't\": \"would not\",\n",
    "                \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
    "                \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color',\n",
    "                'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor',\n",
    "                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What',\n",
    "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I',\n",
    "                'theBest': 'the best', 'howdoes': 'how does', 'Etherium': 'Ethereum',\n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what',\n",
    "                'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "\n",
    "mispell_dict = {k.lower(): v.lower() for k, v in mispell_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd23eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(s):\n",
    "    # making our string lowercase & removing extra spaces\n",
    "    s = str(s).lower().strip()\n",
    "    \n",
    "    # remove contractions.\n",
    "    s = \" \".join([mispell_dict[word] if word in mispell_dict.keys() else word for word in s.split()])\n",
    "    \n",
    "    # removing \\n\n",
    "    s = re.sub('\\n', '', s)\n",
    "    \n",
    "    # put spaces before & after punctuations to make words seprate. Like \"king?\" to \"king\", \"?\".\n",
    "    s = re.sub(r\"([?!,+=—&%\\'\\\";:¿।।।|\\(\\){}\\[\\]//])\", r\" \\1 \", s)\n",
    "    \n",
    "    # Remove more than 2 continues spaces with 1 space.\n",
    "    s = re.sub('[ ]{2,}', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7624794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nc and nh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you do know west teams play against west teams more than east teams right ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>they were underdogs earlier today , but since gronk ' s announcement this afternoon , the vegas line has moved to patriots -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>this meme is not funny none of the \" new york nigga \" ones are.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i could use one of those tools.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0  0       \n",
       "1  0       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       \n",
       "\n",
       "                                                                                                                         comment  \n",
       "0  nc and nh.                                                                                                                     \n",
       "1  you do know west teams play against west teams more than east teams right ?                                                    \n",
       "2  they were underdogs earlier today , but since gronk ' s announcement this afternoon , the vegas line has moved to patriots -1  \n",
       "3  this meme is not funny none of the \" new york nigga \" ones are.                                                                \n",
       "4  i could use one of those tools.                                                                                                "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply preprocessing_text function\n",
    "sarcasm_data['comment'] = sarcasm_data['comment'].apply(preprocessing_text)\n",
    "sarcasm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c5ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total unique words we are going to use.\n",
    "TOTAL_WORDS = 40000\n",
    "\n",
    "# max number of words one sentence can have\n",
    "MAX_LEN = 50\n",
    "\n",
    "# width of of 1D embedding vector\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969e692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.5 s, sys: 149 ms, total: 30.6 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(num_words=TOTAL_WORDS)\n",
    "tokenizer.fit_on_texts(list(sarcasm_data['comment']))\n",
    "\n",
    "train_data = tokenizer.texts_to_sequences(sarcasm_data['comment'])\n",
    "train_data = pad_sequences(train_data, maxlen = MAX_LEN)\n",
    "target = sarcasm_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a1a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'crawl-300d-2M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daec2a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7d274916f649a4b1e5eb383ba4e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open(EMBEDDING_FILE)))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(TOTAL_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b571c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "fname = 'crawl-300d-2M.vec'\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d865760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085baf630dce465797655ebf94e3d1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, i in tqdm(word_index.items()):\n",
    "    if i >= TOTAL_WORDS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b34c14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64721614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# We fix all the random seed so that, we can reproduce the results.\n",
    "seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6edd099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 300)           12000000  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 50, 256)           439296    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12448065 (47.49 MB)\n",
      "Trainable params: 448065 (1.71 MB)\n",
      "Non-trainable params: 12000000 (45.78 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "25270/25270 [==============================] - 2493s 98ms/step - loss: 0.5773 - accuracy: 0.7041 - val_loss: 0.5248 - val_accuracy: 0.7358\n",
      "Epoch 2/5\n",
      "25270/25270 [==============================] - 2480s 98ms/step - loss: 0.5457 - accuracy: 0.7309 - val_loss: 0.5185 - val_accuracy: 0.7387\n",
      "Epoch 3/5\n",
      "25270/25270 [==============================] - 2160s 85ms/step - loss: 0.5300 - accuracy: 0.7429 - val_loss: 0.5199 - val_accuracy: 0.7376\n",
      "Epoch 4/5\n",
      "25270/25270 [==============================] - 2244s 89ms/step - loss: 0.5169 - accuracy: 0.7521 - val_loss: 0.5091 - val_accuracy: 0.7486\n",
      "Epoch 5/5\n",
      "25270/25270 [==============================] - 2277s 90ms/step - loss: 0.5048 - accuracy: 0.7602 - val_loss: 0.5086 - val_accuracy: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c48404d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "input_layer = Input(shape=(MAX_LEN,))\n",
    "embedding_layer = Embedding(TOTAL_WORDS, EMBEDDING_SIZE, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "LSTM_layer = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)\n",
    "maxpool_layer = GlobalMaxPool1D()(LSTM_layer)\n",
    "dense_layer_1 = Dense(32, activation=\"relu\")(maxpool_layer)\n",
    "dropout_1 = Dropout(0.5)(dense_layer_1)\n",
    "dense_layer_2 = Dense(16, activation=\"relu\")(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(dense_layer_2)\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(dropout_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_data, target, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2e3fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f35f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /usr/local/anaconda3/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/anaconda3/lib/python3.11/site-packages (from pydot) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "166b283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/anaconda3/lib/python3.11/site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd88547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821405</th>\n",
       "      <td>1</td>\n",
       "      <td>they were rescued by an army of twitter hash tag.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931327</th>\n",
       "      <td>1</td>\n",
       "      <td>oh ok i guess i am deserving of downvotes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341335</th>\n",
       "      <td>1</td>\n",
       "      <td>it is not magic they use jutsu ugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513336</th>\n",
       "      <td>1</td>\n",
       "      <td>this is so funny and clever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79534</th>\n",
       "      <td>1</td>\n",
       "      <td>he is probably pissed about no new macbook pros.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328832</th>\n",
       "      <td>1</td>\n",
       "      <td>why does not he try to steer out of the way ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118997</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah , we can drop all that stem stuff now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343211</th>\n",
       "      <td>1</td>\n",
       "      <td>for children ' s day they are sending a bunch of adult children to compete against each other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872120</th>\n",
       "      <td>1</td>\n",
       "      <td>amtrak is the greatest example of why laissez faire capitalism is horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277118</th>\n",
       "      <td>1</td>\n",
       "      <td>what do you do with all your buffs ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606485</th>\n",
       "      <td>1</td>\n",
       "      <td>may they live happily ever after together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78901</th>\n",
       "      <td>1</td>\n",
       "      <td>gg overwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872915</th>\n",
       "      <td>1</td>\n",
       "      <td>dae chief keef is not *real* rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559565</th>\n",
       "      <td>1</td>\n",
       "      <td>no that is only in the tekno remixez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>1</td>\n",
       "      <td>you dropped your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158207</th>\n",
       "      <td>1</td>\n",
       "      <td>should have put antifreeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566806</th>\n",
       "      <td>1</td>\n",
       "      <td>leap years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170990</th>\n",
       "      <td>1</td>\n",
       "      <td>con tutta la coca che hanno in corpo va bene se non camminano sulle acque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877074</th>\n",
       "      <td>1</td>\n",
       "      <td>do not worry , this expansion is as much about the alliance as it is the horde !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967012</th>\n",
       "      <td>1</td>\n",
       "      <td>nsfw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  \\\n",
       "821405  1       \n",
       "931327  1       \n",
       "341335  1       \n",
       "513336  1       \n",
       "79534   1       \n",
       "328832  1       \n",
       "118997  1       \n",
       "343211  1       \n",
       "872120  1       \n",
       "277118  1       \n",
       "606485  1       \n",
       "78901   1       \n",
       "872915  1       \n",
       "559565  1       \n",
       "9641    1       \n",
       "158207  1       \n",
       "566806  1       \n",
       "170990  1       \n",
       "877074  1       \n",
       "967012  1       \n",
       "\n",
       "                                                                                              comment  \n",
       "821405  they were rescued by an army of twitter hash tag.                                              \n",
       "931327  oh ok i guess i am deserving of downvotes.                                                     \n",
       "341335  it is not magic they use jutsu ugh                                                             \n",
       "513336  this is so funny and clever                                                                    \n",
       "79534   he is probably pissed about no new macbook pros.                                               \n",
       "328832  why does not he try to steer out of the way ?                                                  \n",
       "118997  yeah , we can drop all that stem stuff now.                                                    \n",
       "343211  for children ' s day they are sending a bunch of adult children to compete against each other  \n",
       "872120  amtrak is the greatest example of why laissez faire capitalism is horrible                     \n",
       "277118  what do you do with all your buffs ?                                                           \n",
       "606485  may they live happily ever after together...                                                   \n",
       "78901   gg overwatch                                                                                   \n",
       "872915  dae chief keef is not *real* rap                                                               \n",
       "559565  no that is only in the tekno remixez                                                           \n",
       "9641    you dropped your                                                                               \n",
       "158207  should have put antifreeze                                                                     \n",
       "566806  leap years.                                                                                    \n",
       "170990  con tutta la coca che hanno in corpo va bene se non camminano sulle acque                      \n",
       "877074  do not worry , this expansion is as much about the alliance as it is the horde !               \n",
       "967012  nsfw                                                                                           "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_data[sarcasm_data['label']==1].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "373142d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818764</th>\n",
       "      <td>0</td>\n",
       "      <td>capitalism does not work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24883</th>\n",
       "      <td>0</td>\n",
       "      <td>as an american that has watched every simpsons episode twice , it just clicked for me too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780867</th>\n",
       "      <td>0</td>\n",
       "      <td>i could actually see that working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187576</th>\n",
       "      <td>0</td>\n",
       "      <td>you need to quantify ' significant ' .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943841</th>\n",
       "      <td>0</td>\n",
       "      <td>scotland ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790173</th>\n",
       "      <td>0</td>\n",
       "      <td>cutty is dennis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474798</th>\n",
       "      <td>0</td>\n",
       "      <td>the biceps are not always with you my friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109965</th>\n",
       "      <td>0</td>\n",
       "      <td>yeah , he will move over and follow conor to wwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>0</td>\n",
       "      <td>i have a feeling armada was just told to sit and play a friendly with abu before going on stage and he was too frustrated at the mang0 loss to be a part of it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70072</th>\n",
       "      <td>0</td>\n",
       "      <td>that and shills are afraid of words alone , they are definitely not getting remotely close to alligators.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544649</th>\n",
       "      <td>0</td>\n",
       "      <td>basket case - green day , or 21st century boy by bad religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845905</th>\n",
       "      <td>0</td>\n",
       "      <td>that full disenchant value , all gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909995</th>\n",
       "      <td>0</td>\n",
       "      <td>we all have to adjust , give him a break !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332988</th>\n",
       "      <td>0</td>\n",
       "      <td>you are not factoring in how much he wants it to happen !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879911</th>\n",
       "      <td>0</td>\n",
       "      <td>it will not let me mess with the monitor settings until there is a signal being outputted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139109</th>\n",
       "      <td>0</td>\n",
       "      <td>i will be there , tammy !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13445</th>\n",
       "      <td>0</td>\n",
       "      <td>also the keyboard and mouse are both stand-ins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936162</th>\n",
       "      <td>0</td>\n",
       "      <td>#ha...ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318777</th>\n",
       "      <td>0</td>\n",
       "      <td>if the second set of zeroes are unluckier than the first is it still a palindrome ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173629</th>\n",
       "      <td>0</td>\n",
       "      <td>alright thanks for the reply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  \\\n",
       "818764  0       \n",
       "24883   0       \n",
       "780867  0       \n",
       "187576  0       \n",
       "943841  0       \n",
       "790173  0       \n",
       "474798  0       \n",
       "109965  0       \n",
       "51784   0       \n",
       "70072   0       \n",
       "544649  0       \n",
       "845905  0       \n",
       "909995  0       \n",
       "332988  0       \n",
       "879911  0       \n",
       "139109  0       \n",
       "13445   0       \n",
       "936162  0       \n",
       "318777  0       \n",
       "173629  0       \n",
       "\n",
       "                                                                                                                                                               comment  \n",
       "818764  capitalism does not work.                                                                                                                                       \n",
       "24883   as an american that has watched every simpsons episode twice , it just clicked for me too.                                                                      \n",
       "780867  i could actually see that working...                                                                                                                            \n",
       "187576  you need to quantify ' significant ' .                                                                                                                          \n",
       "943841  scotland ?                                                                                                                                                      \n",
       "790173  cutty is dennis.                                                                                                                                                \n",
       "474798  the biceps are not always with you my friend                                                                                                                    \n",
       "109965  yeah , he will move over and follow conor to wwe                                                                                                                \n",
       "51784   i have a feeling armada was just told to sit and play a friendly with abu before going on stage and he was too frustrated at the mang0 loss to be a part of it  \n",
       "70072   that and shills are afraid of words alone , they are definitely not getting remotely close to alligators.                                                       \n",
       "544649  basket case - green day , or 21st century boy by bad religion                                                                                                   \n",
       "845905  that full disenchant value , all gone.                                                                                                                          \n",
       "909995  we all have to adjust , give him a break !                                                                                                                      \n",
       "332988  you are not factoring in how much he wants it to happen !                                                                                                       \n",
       "879911  it will not let me mess with the monitor settings until there is a signal being outputted.                                                                      \n",
       "139109  i will be there , tammy !                                                                                                                                       \n",
       "13445   also the keyboard and mouse are both stand-ins                                                                                                                  \n",
       "936162  #ha...ok                                                                                                                                                        \n",
       "318777  if the second set of zeroes are unluckier than the first is it still a palindrome ?                                                                             \n",
       "173629  alright thanks for the reply                                                                                                                                    "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_data[sarcasm_data['label']==0].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d53e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high school shootings are the modern u.s theater pieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  290,  407, 4467,   13,\n",
       "           1, 1275,  332,   49, 4195, 2463]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"High school shootings are the modern U.S theatre pieces\"\n",
    "sentence = preprocessing_text(sentence)\n",
    "print(sentence)\n",
    "\n",
    "sentence = tokenizer.texts_to_sequences([sentence])\n",
    "sentence = pad_sequences(sentence, maxlen = MAX_LEN)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56295bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3119205"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(sentence)\n",
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad793f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, it's saying sentence have probability of 31.192 percent\n"
     ]
    }
   ],
   "source": [
    "print(\"So, it's saying sentence have probability of %.3f percent\"%(prediction[0][0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54b69f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is not it great that , your girlfriend dumped you ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    2,    7,    8,\n",
       "         121,   10,   39, 1642, 9632,    6]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Isn't it great that, your girlfriend dumped you?\"\n",
    "sentence = preprocessing_text(sentence)\n",
    "print(sentence)\n",
    "\n",
    "sentence = tokenizer.texts_to_sequences([sentence])\n",
    "sentence = pad_sequences(sentence, maxlen = MAX_LEN)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8315aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6319539"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the prediction.\n",
    "prediction = model.predict(sentence)\n",
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa41eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
