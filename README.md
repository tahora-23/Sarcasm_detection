# Sarcasm_detection
Sarcasm_detection
Team Sarcasm: Bryan & Tahora 
Goal: To research train and implement Deep Learning Model concerned with the classification of individual sarcastic comments.
Process: 
Data Collection: Reddit dataset


Preprocessing: Cleaning, Tokenizing, Stemming, Lemmatization


Feature Engineering: Convert text data into numerical representations (word embedding, BERT embeddings.Extract additional features like sentiment scores.

Model Selection:
Transformer-based models

Model Training:
Split the data into training, validation and testing sets.
Train the chosen model optimizing a suitable loss function (e.g binary cross-entropy)
Tune hyperparameters using the validation set to improve model performance.

Model Evaluation:
Evaluate the trained model using metrics like accuracy, precision, recall and F1.

Fine-tuning and Iteration


Tools: Python and Google colab 



Dataset: https://www.kaggle.com/datasets/danofer/sarcasm?select=train-balanced-sarcasm.csv
Raddit Sarcasm dataset contains 1.3 million  rows and 10 columns from which we use 2 columns (label and comments)

https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%203.ipynb


